# 梯度累加
## Gradient Accumulation
定义：梯度累加，就是将多次计算的梯度值进行累加，然后进行一次性的参数更新  
使用场景：常用于单卡训练显存不足时，将其分为多个小的mini-batch，每个step送入一个mini-batch获得梯度，但是不马上更新参数，而是将多次获得的梯度进行累加后再更新参数，以达到模拟单次使用大的batch训练的目的

## 代码
```
for i , (context,label) in enumerate(train_loader):
    preds = model(context) # 前向传播
    loss = loss_function(preds,label)  # 计算loss
    loss = loss / accumulation_steps   # 核心步骤
    loss.backward() # 计算梯度，但是要知道，backward只是计算了梯度，并没有将参数更新，在这里用于计算，随后累加梯度
    if (i+1) % accumulation_steps == 0:  # 只有当累积到accumulation_steps整数倍的时候
        optimizer.step()  # 参数才会更新
        optimizer.zero_grad()  # 清除之前累积的梯度
```
## 代码解释
loss = loss / accimulation_steps  
这一句代码的作用主要是看loss的计算形式是基于average还是sum  
当loss的计算形式为sum时，计算梯度更新的公式如下：  
<div align=center>
  <img src="https://github.com/user-attachments/assets/6600c22c-773b-4817-b518-1d86e8df2c64" width="800" />
</div>

由于loss.backward()是自动累加梯度的，只要没有手动将梯度清零，它会基于之前的梯度累加，因此不需要做额外的操作，在这种情况下 loss = loss/accumulation_steps是额外的操作  

  但如果loss的计算方式是基于average，即如下图
  <div align=center>
  <img src="https://github.com/user-attachments/assets/e6465862-c5df-4523-b89a-dd0a3118d110" width="800" />
</div>
此时loss = loss / accumulation_steps就是必要的步骤了
