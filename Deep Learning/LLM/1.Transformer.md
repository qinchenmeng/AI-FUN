论文地址：https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf

# 1、Transformer介绍

Transformer的提出彻底改变了自然语言处理和深度学习领域，它克服了RNN和CNN在处理长序列数据时的局限性，实现了更高效的并行计算和最强的建模能力  

Transormer的核心创新在于**自注意力机制**和**前馈神经网络**，完全摒弃了RNN结构，使得模型能够全局建模序列数据  

它的提出带来了NLP领域的BERT、GPT、T5和CV领域的ViT、Swin Transformer以及后续的多模态大模型

# 2、模型结构

Transformer由编码器和解码器组成，每层包含相同的层级结构  
<div style="text-align: center;">
  <img src="https://github.com/user-attachments/assets/80fb98d0-ff3c-4189-ae85-252294d930ba" width="300" />
</div>

