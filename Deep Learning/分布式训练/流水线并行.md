# 流水线并行  
## 1.优化目标  
分布式训练的总体目标是什么呢？  
· 能训练更大的模型  
· 能更快的训练模型  
## 2.模型并行
当一个单卡装不下的大模型时，最直接的解决办法是，把模型隔成不同的层，从而放到不同的GPU上  
<div align=center>
  <img src="https://github.com/user-attachments/assets/0d696de0-9f84-4e6f-b5b6-02c8ba256063" width="500" />
</div>
