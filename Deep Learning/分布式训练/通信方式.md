# 分布式训练中通信方式介绍
## 一、All-Gather 
**核心功能**：将每个节点的部分数据汇总到所有结点，最终所有节点拥有完整数据副本  
**适用场景**：模型并行中的参数同步、全局统计信息聚合
![image](https://github.com/user-attachments/assets/b362025a-087c-472b-a4a6-417088fc5e46)
工作流程示例：  
· 数据分块：每个节点将本地数据划分为与节点数相同的块【如4个节点分为4块】  
· 环形传递：节点按逻辑环依次发送和接收数据块（例如节点1发送块1→节点2，同时接收节点4的块4）。  
· 多轮迭代：经过N-1轮（N为节点数），所有节点通过拼接累积数据块完成全局同步。

## 二、Reduce-Scatter
**核心功能**：先对多节点数据进行规约（如求和），再将结果分散到各节点，使每个节点仅保留部分规约结果。
**适用场景**：ZeRO显存优化、梯度分片更新。
![image](https://github.com/user-attachments/assets/dee9e2c3-6282-49d9-9290-d8be9a4fd225)
工作流程示例：  
规约阶段（Reduce）
· 节点对相同位置的数据块执行并行规约（如GPU0~3分别对块0~3求和）  
· 关键优化：利用环形拓扑减少带宽竞争，规约与传输并行。  
分散阶段（Scatter）  
· 将规约后的数据块按节点索引分发（如GPU0接收块0，GPU1接收块1）。
## 三、All-Gather和Reduce-Scatter区别
### 3.1 数据处理方式
· All-Gather：只进行数据收集和分发，不进行任何计算或规约操作  
· Reduce-Scatter：先进行数据规约（reduce），然后再进行数据分散（scatter）
### 3.2 最终结果
· All-Gather：每个节点拥有所有节点的数据副本  
· Reduce-Scatter：每个节点只拥有部分规约后的数据，而不是所有的数据
## 四、All-Reduce
**核心功能**：将全局数据规约后同步至所有节点，等价于 Reduce-Scatter + All-Gather。
**适用场景**：Ring All-Reduce是一种主流方式
